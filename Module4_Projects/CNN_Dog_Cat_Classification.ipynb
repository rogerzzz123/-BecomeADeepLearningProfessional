{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f29527f-aeed-489a-b699-a1931d325c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c584031-70f4-40f4-ab57-f0bcacd4eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a679aa2-958a-4517-8641-848a83e6f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = image.ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea7b372-3f7e-41d5-bf8a-317576fea179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x1643f9450>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32da08dd-1dfc-4121-9132-5366264ded37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 446280\n",
      "-rw-r--r--  1 ningning  staff       3706  2 Oct 20:23 CNN_Dog_Cat_Classification.ipynb\n",
      "-rw-r--r--  1 ningning  staff  228487605 30 Sep  2019 cat-and-dog.zip\n",
      "drwxr-xr-x  3 ningning  staff         96  2 Oct 16:55 \u001b[34mtest_set\u001b[m\u001b[m\n",
      "drwxr-xr-x  3 ningning  staff         96  2 Oct 16:55 \u001b[34mtraining_set\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76e8620-6c2a-42c4-b456-d83f552cd694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 1 classes.\n",
      "Found 2023 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('training_set',target_size=(224,224),batch_size=32, class_mode=\"binary\")\n",
    "val_generator = test_datagen.flow_from_directory('test_set',target_size=(224,224),batch_size=32, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "091045bd-e165-4e48-8b69-81c199b5e837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images shape: (32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_generator:\n",
    "    print(\"Batch of images shape:\", images.shape)  # Shape should be (batch_size, 300, 300, 3)\n",
    "    break  # Remove this break if you want to check more batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673962e-b1f0-4677-bfd3-8567a02a69f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cffb5819-9ced-417c-becc-a3b2ffd17d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 220, 220, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 110, 110, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 110, 110, 64)      0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 108, 108, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 54, 54, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 52, 52, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 26, 26, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 26, 26, 256)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 173056)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               22151296  \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,550,081\n",
      "Trainable params: 22,550,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape = (224,224,3)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b6a5515-0916-4e4d-ba44-1616bf7642cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-06 18:39:58.841290: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-06 18:58:51.949358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 1214s 5s/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 8.3496e-11 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "251/251 [==============================] - 1228s 5s/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 7.3835e-26 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "251/251 [==============================] - 816s 3s/step - loss: 2.7176e-10 - accuracy: 1.0000 - val_loss: 6.2729e-26 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "251/251 [==============================] - 718s 3s/step - loss: 9.9804e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "251/251 [==============================] - 763s 3s/step - loss: 7.3797e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "111/251 [============>.................] - ETA: 10:20 - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-06 20:07:10.024555: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n",
      "    yield x[i]\n",
      "          ~^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n",
      "    img = image_utils.load_img(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n",
      "    with open(path, \"rb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n",
      "\n",
      "\n",
      "2024-10-06 20:07:10.024619: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n",
      "    yield x[i]\n",
      "          ~^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n",
      "    img = image_utils.load_img(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n",
      "    with open(path, \"rb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/251 [============>.................] - ETA: 10:16 - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-06 20:07:15.032079: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n",
      "    yield x[i]\n",
      "          ~^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n",
      "    img = image_utils.load_img(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n",
      "    with open(path, \"rb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\nTraceback (most recent call last):\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n          ~^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^\n\nFileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2023]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(train_generator, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mval_generator)\n",
      "File \u001b[0;32m~/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\nTraceback (most recent call last):\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n          ~^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/ningning/anaconda3/envs/cnn/lib/python3.11/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^\n\nFileNotFoundError: [Errno 2] No such file or directory: 'training_set/training_set/dogs/dog.1041.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2023]"
     ]
    }
   ],
   "source": [
    "hist=model.fit(train_generator, epochs=80, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb2ab4-3e99-4fa8-a0f6-6792e30cbcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
